{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenización por caracteres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Nicolas\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset canciones de bandas de habla inglés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"Odyssey of the Dragonlords.txt\", \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "    article_text = \" \".join(line.strip() for line in lines)\n",
        "\n",
        "article_text = article_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WBE0sSYuB-E6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'welcome to odyssey of the dragonlords. this booklet will provide you with everything you need to run an epic campaign in the forgotten land of thylea. odyssey of the dragonlords is heavily inspired by stories from ancient greek mythology. as we designed the campaign, we sought to include ideas from many different sources: the odyssey, the iliad, jason and the argonauts, the oresteia, and others. however, thylea is not ancient greece. you will not find zeus, athena, or apollo among the gods. as you explore thylea, you will encounter familiar tropes, monsters, and treasures from greek mythology-but the rules are different here. mortals have only recently come to these lands. the world of thylea blends high fantasy with the trappings of ancient history. elves, dwarves, and halflings now live alongside minotaurs, centaurs, and satyrs. our goal is to make your party feel like heroes from one of the greatest stories ever told-but the ultimate end of that story is entirely within your power. '"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# en article text se encuentra el texto de todo el libro\n",
        "article_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
        "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(article_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "VwTK6xgLJd8q"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{' ',\n",
              " '!',\n",
              " '\"',\n",
              " '%',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '\\xad',\n",
              " '•',\n",
              " '\\uf075'}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chars_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PwGVSKOiJ5bj"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[112,\n",
              " 62,\n",
              " 113,\n",
              " 53,\n",
              " 100,\n",
              " 12,\n",
              " 62,\n",
              " 73,\n",
              " 29,\n",
              " 100,\n",
              " 73,\n",
              " 100,\n",
              " 64,\n",
              " 15,\n",
              " 25,\n",
              " 25,\n",
              " 62,\n",
              " 15,\n",
              " 73,\n",
              " 100,\n",
              " 66,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 73,\n",
              " 64,\n",
              " 96,\n",
              " 21,\n",
              " 8,\n",
              " 100,\n",
              " 44,\n",
              " 113,\n",
              " 100,\n",
              " 96,\n",
              " 64,\n",
              " 25,\n",
              " 114,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 9,\n",
              " 25,\n",
              " 73,\n",
              " 84,\n",
              " 100,\n",
              " 100,\n",
              " 39,\n",
              " 113,\n",
              " 62,\n",
              " 29,\n",
              " 73,\n",
              " 112,\n",
              " 9,\n",
              " 113,\n",
              " 113,\n",
              " 73,\n",
              " 78,\n",
              " 96,\n",
              " 100,\n",
              " 68,\n",
              " 9,\n",
              " 64,\n",
              " 62,\n",
              " 73,\n",
              " 15,\n",
              " 100,\n",
              " 4,\n",
              " 73,\n",
              " 112,\n",
              " 9,\n",
              " 29,\n",
              " 60,\n",
              " 73,\n",
              " 62,\n",
              " 68,\n",
              " 62,\n",
              " 96,\n",
              " 15,\n",
              " 29,\n",
              " 60,\n",
              " 9,\n",
              " 44,\n",
              " 8,\n",
              " 73,\n",
              " 15,\n",
              " 100,\n",
              " 4,\n",
              " 73,\n",
              " 44,\n",
              " 62,\n",
              " 62,\n",
              " 64,\n",
              " 73,\n",
              " 29,\n",
              " 100,\n",
              " 73,\n",
              " 96,\n",
              " 4,\n",
              " 44,\n",
              " 73,\n",
              " 21,\n",
              " 44,\n",
              " 73,\n",
              " 62,\n",
              " 78,\n",
              " 9,\n",
              " 53,\n",
              " 73,\n",
              " 53,\n",
              " 21,\n",
              " 12,\n",
              " 78,\n",
              " 21,\n",
              " 9,\n",
              " 8,\n",
              " 44,\n",
              " 73,\n",
              " 9,\n",
              " 44,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 73,\n",
              " 66,\n",
              " 100,\n",
              " 96,\n",
              " 8,\n",
              " 100,\n",
              " 29,\n",
              " 29,\n",
              " 62,\n",
              " 44,\n",
              " 73,\n",
              " 113,\n",
              " 21,\n",
              " 44,\n",
              " 64,\n",
              " 73,\n",
              " 100,\n",
              " 66,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 15,\n",
              " 113,\n",
              " 62,\n",
              " 21,\n",
              " 114,\n",
              " 73,\n",
              " 100,\n",
              " 64,\n",
              " 15,\n",
              " 25,\n",
              " 25,\n",
              " 62,\n",
              " 15,\n",
              " 73,\n",
              " 100,\n",
              " 66,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 73,\n",
              " 64,\n",
              " 96,\n",
              " 21,\n",
              " 8,\n",
              " 100,\n",
              " 44,\n",
              " 113,\n",
              " 100,\n",
              " 96,\n",
              " 64,\n",
              " 25,\n",
              " 73,\n",
              " 9,\n",
              " 25,\n",
              " 73,\n",
              " 60,\n",
              " 62,\n",
              " 21,\n",
              " 68,\n",
              " 9,\n",
              " 113,\n",
              " 15,\n",
              " 73,\n",
              " 9,\n",
              " 44,\n",
              " 25,\n",
              " 78,\n",
              " 9,\n",
              " 96,\n",
              " 62,\n",
              " 64,\n",
              " 73,\n",
              " 84,\n",
              " 15,\n",
              " 73,\n",
              " 25,\n",
              " 29,\n",
              " 100,\n",
              " 96,\n",
              " 9,\n",
              " 62,\n",
              " 25,\n",
              " 73,\n",
              " 66,\n",
              " 96,\n",
              " 100,\n",
              " 12,\n",
              " 73,\n",
              " 21,\n",
              " 44,\n",
              " 53,\n",
              " 9,\n",
              " 62,\n",
              " 44,\n",
              " 29,\n",
              " 73,\n",
              " 8,\n",
              " 96,\n",
              " 62,\n",
              " 62,\n",
              " 39,\n",
              " 73,\n",
              " 12,\n",
              " 15,\n",
              " 29,\n",
              " 60,\n",
              " 100,\n",
              " 113,\n",
              " 100,\n",
              " 8,\n",
              " 15,\n",
              " 114,\n",
              " 73,\n",
              " 21,\n",
              " 25,\n",
              " 73,\n",
              " 112,\n",
              " 62,\n",
              " 73,\n",
              " 64,\n",
              " 62,\n",
              " 25,\n",
              " 9,\n",
              " 8,\n",
              " 44,\n",
              " 62,\n",
              " 64,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 73,\n",
              " 53,\n",
              " 21,\n",
              " 12,\n",
              " 78,\n",
              " 21,\n",
              " 9,\n",
              " 8,\n",
              " 44,\n",
              " 10,\n",
              " 73,\n",
              " 112,\n",
              " 62,\n",
              " 73,\n",
              " 25,\n",
              " 100,\n",
              " 4,\n",
              " 8,\n",
              " 60,\n",
              " 29,\n",
              " 73,\n",
              " 29,\n",
              " 100,\n",
              " 73,\n",
              " 9,\n",
              " 44,\n",
              " 53,\n",
              " 113,\n",
              " 4,\n",
              " 64,\n",
              " 62,\n",
              " 73,\n",
              " 9,\n",
              " 64,\n",
              " 62,\n",
              " 21,\n",
              " 25,\n",
              " 73,\n",
              " 66,\n",
              " 96,\n",
              " 100,\n",
              " 12,\n",
              " 73,\n",
              " 12,\n",
              " 21,\n",
              " 44,\n",
              " 15,\n",
              " 73,\n",
              " 64,\n",
              " 9,\n",
              " 66,\n",
              " 66,\n",
              " 62,\n",
              " 96,\n",
              " 62,\n",
              " 44,\n",
              " 29,\n",
              " 73,\n",
              " 25,\n",
              " 100,\n",
              " 4,\n",
              " 96,\n",
              " 53,\n",
              " 62,\n",
              " 25,\n",
              " 6,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 73,\n",
              " 100,\n",
              " 64,\n",
              " 15,\n",
              " 25,\n",
              " 25,\n",
              " 62,\n",
              " 15,\n",
              " 10,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 73,\n",
              " 9,\n",
              " 113,\n",
              " 9,\n",
              " 21,\n",
              " 64,\n",
              " 10,\n",
              " 73,\n",
              " 54,\n",
              " 21,\n",
              " 25,\n",
              " 100,\n",
              " 44,\n",
              " 73,\n",
              " 21,\n",
              " 44,\n",
              " 64,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 73,\n",
              " 21,\n",
              " 96,\n",
              " 8,\n",
              " 100,\n",
              " 44,\n",
              " 21,\n",
              " 4,\n",
              " 29,\n",
              " 25,\n",
              " 10,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 73,\n",
              " 100,\n",
              " 96,\n",
              " 62,\n",
              " 25,\n",
              " 29,\n",
              " 62,\n",
              " 9,\n",
              " 21,\n",
              " 10,\n",
              " 73,\n",
              " 21,\n",
              " 44,\n",
              " 64,\n",
              " 73,\n",
              " 100,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 96,\n",
              " 25,\n",
              " 114,\n",
              " 73,\n",
              " 60,\n",
              " 100,\n",
              " 112,\n",
              " 62,\n",
              " 68,\n",
              " 62,\n",
              " 96,\n",
              " 10,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 15,\n",
              " 113,\n",
              " 62,\n",
              " 21,\n",
              " 73,\n",
              " 9,\n",
              " 25,\n",
              " 73,\n",
              " 44,\n",
              " 100,\n",
              " 29,\n",
              " 73,\n",
              " 21,\n",
              " 44,\n",
              " 53,\n",
              " 9,\n",
              " 62,\n",
              " 44,\n",
              " 29,\n",
              " 73,\n",
              " 8,\n",
              " 96,\n",
              " 62,\n",
              " 62,\n",
              " 53,\n",
              " 62,\n",
              " 114,\n",
              " 73,\n",
              " 15,\n",
              " 100,\n",
              " 4,\n",
              " 73,\n",
              " 112,\n",
              " 9,\n",
              " 113,\n",
              " 113,\n",
              " 73,\n",
              " 44,\n",
              " 100,\n",
              " 29,\n",
              " 73,\n",
              " 66,\n",
              " 9,\n",
              " 44,\n",
              " 64,\n",
              " 73,\n",
              " 58,\n",
              " 62,\n",
              " 4,\n",
              " 25,\n",
              " 10,\n",
              " 73,\n",
              " 21,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 44,\n",
              " 21,\n",
              " 10,\n",
              " 73,\n",
              " 100,\n",
              " 96,\n",
              " 73,\n",
              " 21,\n",
              " 78,\n",
              " 100,\n",
              " 113,\n",
              " 113,\n",
              " 100,\n",
              " 73,\n",
              " 21,\n",
              " 12,\n",
              " 100,\n",
              " 44,\n",
              " 8,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 73,\n",
              " 8,\n",
              " 100,\n",
              " 64,\n",
              " 25,\n",
              " 114,\n",
              " 73,\n",
              " 21,\n",
              " 25,\n",
              " 73,\n",
              " 15,\n",
              " 100,\n",
              " 4,\n",
              " 73,\n",
              " 62,\n",
              " 119,\n",
              " 78,\n",
              " 113,\n",
              " 100,\n",
              " 96,\n",
              " 62,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 15,\n",
              " 113,\n",
              " 62,\n",
              " 21,\n",
              " 10,\n",
              " 73,\n",
              " 15,\n",
              " 100,\n",
              " 4,\n",
              " 73,\n",
              " 112,\n",
              " 9,\n",
              " 113,\n",
              " 113,\n",
              " 73,\n",
              " 62,\n",
              " 44,\n",
              " 53,\n",
              " 100,\n",
              " 4,\n",
              " 44,\n",
              " 29,\n",
              " 62,\n",
              " 96,\n",
              " 73,\n",
              " 66,\n",
              " 21,\n",
              " 12,\n",
              " 9,\n",
              " 113,\n",
              " 9,\n",
              " 21,\n",
              " 96,\n",
              " 73,\n",
              " 29,\n",
              " 96,\n",
              " 100,\n",
              " 78,\n",
              " 62,\n",
              " 25,\n",
              " 10,\n",
              " 73,\n",
              " 12,\n",
              " 100,\n",
              " 44,\n",
              " 25,\n",
              " 29,\n",
              " 62,\n",
              " 96,\n",
              " 25,\n",
              " 10,\n",
              " 73,\n",
              " 21,\n",
              " 44,\n",
              " 64,\n",
              " 73,\n",
              " 29,\n",
              " 96,\n",
              " 62,\n",
              " 21,\n",
              " 25,\n",
              " 4,\n",
              " 96,\n",
              " 62,\n",
              " 25,\n",
              " 73,\n",
              " 66,\n",
              " 96,\n",
              " 100,\n",
              " 12,\n",
              " 73,\n",
              " 8,\n",
              " 96,\n",
              " 62,\n",
              " 62,\n",
              " 39,\n",
              " 73,\n",
              " 12,\n",
              " 15,\n",
              " 29,\n",
              " 60,\n",
              " 100,\n",
              " 113,\n",
              " 100,\n",
              " 8,\n",
              " 15,\n",
              " 107,\n",
              " 84,\n",
              " 4,\n",
              " 29,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 73,\n",
              " 96,\n",
              " 4,\n",
              " 113,\n",
              " 62,\n",
              " 25,\n",
              " 73,\n",
              " 21,\n",
              " 96,\n",
              " 62,\n",
              " 73,\n",
              " 64,\n",
              " 9,\n",
              " 66,\n",
              " 66,\n",
              " 62,\n",
              " 96,\n",
              " 62,\n",
              " 44,\n",
              " 29,\n",
              " 73,\n",
              " 60,\n",
              " 62,\n",
              " 96,\n",
              " 62,\n",
              " 114,\n",
              " 73,\n",
              " 12,\n",
              " 100,\n",
              " 96,\n",
              " 29,\n",
              " 21,\n",
              " 113,\n",
              " 25,\n",
              " 73,\n",
              " 60,\n",
              " 21,\n",
              " 68,\n",
              " 62,\n",
              " 73,\n",
              " 100,\n",
              " 44,\n",
              " 113,\n",
              " 15,\n",
              " 73,\n",
              " 96,\n",
              " 62,\n",
              " 53,\n",
              " 62,\n",
              " 44,\n",
              " 29,\n",
              " 113,\n",
              " 15,\n",
              " 73,\n",
              " 53,\n",
              " 100,\n",
              " 12,\n",
              " 62,\n",
              " 73,\n",
              " 29,\n",
              " 100,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 25,\n",
              " 62,\n",
              " 73,\n",
              " 113,\n",
              " 21,\n",
              " 44,\n",
              " 64,\n",
              " 25,\n",
              " 114,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 73,\n",
              " 112,\n",
              " 100,\n",
              " 96,\n",
              " 113,\n",
              " 64,\n",
              " 73,\n",
              " 100,\n",
              " 66,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 15,\n",
              " 113,\n",
              " 62,\n",
              " 21,\n",
              " 73,\n",
              " 84,\n",
              " 113,\n",
              " 62,\n",
              " 44,\n",
              " 64,\n",
              " 25,\n",
              " 73,\n",
              " 60,\n",
              " 9,\n",
              " 8,\n",
              " 60,\n",
              " 73,\n",
              " 66,\n",
              " 21,\n",
              " 44,\n",
              " 29,\n",
              " 21,\n",
              " 25,\n",
              " 15,\n",
              " 73,\n",
              " 112,\n",
              " 9,\n",
              " 29,\n",
              " 60,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 73,\n",
              " 29,\n",
              " 96,\n",
              " 21,\n",
              " 78,\n",
              " 78,\n",
              " 9,\n",
              " 44,\n",
              " 8,\n",
              " 25,\n",
              " 73,\n",
              " 100,\n",
              " 66,\n",
              " 73,\n",
              " 21,\n",
              " 44,\n",
              " 53,\n",
              " 9,\n",
              " 62,\n",
              " 44,\n",
              " 29,\n",
              " 73,\n",
              " 60,\n",
              " 9,\n",
              " 25,\n",
              " 29,\n",
              " 100,\n",
              " 96,\n",
              " 15,\n",
              " 114,\n",
              " 73,\n",
              " 62,\n",
              " 113,\n",
              " 68,\n",
              " 62,\n",
              " 25,\n",
              " 10,\n",
              " 73,\n",
              " 64,\n",
              " 112,\n",
              " 21,\n",
              " 96,\n",
              " 68,\n",
              " 62,\n",
              " 25,\n",
              " 10,\n",
              " 73,\n",
              " 21,\n",
              " 44,\n",
              " 64,\n",
              " 73,\n",
              " 60,\n",
              " 21,\n",
              " 113,\n",
              " 66,\n",
              " 113,\n",
              " 9,\n",
              " 44,\n",
              " 8,\n",
              " 25,\n",
              " 73,\n",
              " 44,\n",
              " 100,\n",
              " 112,\n",
              " 73,\n",
              " 113,\n",
              " 9,\n",
              " 68,\n",
              " 62,\n",
              " 73,\n",
              " 21,\n",
              " 113,\n",
              " 100,\n",
              " 44,\n",
              " 8,\n",
              " 25,\n",
              " 9,\n",
              " 64,\n",
              " 62,\n",
              " 73,\n",
              " 12,\n",
              " 9,\n",
              " 44,\n",
              " 100,\n",
              " 29,\n",
              " 21,\n",
              " 4,\n",
              " 96,\n",
              " 25,\n",
              " 10,\n",
              " 73,\n",
              " 53,\n",
              " 62,\n",
              " 44,\n",
              " 29,\n",
              " 21,\n",
              " 4,\n",
              " 96,\n",
              " 25,\n",
              " 10,\n",
              " 73,\n",
              " 21,\n",
              " 44,\n",
              " 64,\n",
              " 73,\n",
              " 25,\n",
              " 21,\n",
              " 29,\n",
              " 15,\n",
              " 96,\n",
              " 25,\n",
              " 114,\n",
              " 73,\n",
              " 100,\n",
              " 4,\n",
              " 96,\n",
              " 73,\n",
              " 8,\n",
              " 100,\n",
              " 21,\n",
              " 113,\n",
              " 73,\n",
              " 9,\n",
              " 25,\n",
              " 73,\n",
              " 29,\n",
              " 100,\n",
              " 73,\n",
              " 12,\n",
              " 21,\n",
              " 39,\n",
              " 62,\n",
              " 73,\n",
              " 15,\n",
              " 100,\n",
              " 4,\n",
              " 96,\n",
              " 73,\n",
              " 78,\n",
              " 21,\n",
              " 96,\n",
              " 29,\n",
              " 15,\n",
              " 73,\n",
              " 66,\n",
              " 62,\n",
              " 62,\n",
              " 113,\n",
              " 73,\n",
              " 113,\n",
              " 9,\n",
              " 39,\n",
              " 62,\n",
              " 73,\n",
              " 60,\n",
              " 62,\n",
              " 96,\n",
              " 100,\n",
              " 62,\n",
              " 25,\n",
              " 73,\n",
              " 66,\n",
              " 96,\n",
              " 100,\n",
              " 12,\n",
              " 73,\n",
              " 100,\n",
              " 44,\n",
              " 62,\n",
              " 73,\n",
              " 100,\n",
              " 66,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 73,\n",
              " 8,\n",
              " 96,\n",
              " 62,\n",
              " 21,\n",
              " 29,\n",
              " 62,\n",
              " 25,\n",
              " 29,\n",
              " 73,\n",
              " 25,\n",
              " 29,\n",
              " 100,\n",
              " 96,\n",
              " 9,\n",
              " 62,\n",
              " 25,\n",
              " 73,\n",
              " 62,\n",
              " 68,\n",
              " 62,\n",
              " 96,\n",
              " 73,\n",
              " 29,\n",
              " 100,\n",
              " 113,\n",
              " 64,\n",
              " 107,\n",
              " 84,\n",
              " 4,\n",
              " 29,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 62,\n",
              " 73,\n",
              " 4,\n",
              " 113,\n",
              " 29,\n",
              " 9,\n",
              " 12,\n",
              " 21,\n",
              " 29,\n",
              " 62,\n",
              " 73,\n",
              " 62,\n",
              " 44,\n",
              " 64,\n",
              " 73,\n",
              " 100,\n",
              " 66,\n",
              " 73,\n",
              " 29,\n",
              " 60,\n",
              " 21,\n",
              " 29,\n",
              " 73,\n",
              " 25,\n",
              " 29,\n",
              " 100,\n",
              " 96,\n",
              " 15,\n",
              " 73,\n",
              " 9,\n",
              " 25,\n",
              " 73,\n",
              " 62,\n",
              " 44,\n",
              " 29,\n",
              " 9,\n",
              " 96,\n",
              " 62,\n",
              " 113,\n",
              " 15,\n",
              " 73,\n",
              " 112,\n",
              " 9,\n",
              " 29,\n",
              " 60,\n",
              " 9,\n",
              " 44,\n",
              " 73,\n",
              " 15,\n",
              " 100,\n",
              " 4,\n",
              " 96,\n",
              " 73,\n",
              " 78,\n",
              " 100,\n",
              " 112,\n",
              " 62,\n",
              " 96,\n",
              " 114,\n",
              " 73]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WSSmg9jtKP0T"
      },
      "outputs": [],
      "source": [
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NmxQdxl8LRCg"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vken7O4ETsAJ"
      },
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
        "\n",
        "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
        "\n",
        "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KFAyA4zCWE-5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1506650, 100)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qcKRl70HFTzG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([112,  62, 113,  53, 100,  12,  62,  73,  29, 100])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TVpLCKSZFXZO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 62, 113,  53, 100,  12,  62,  73,  29, 100,  73])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wOFCR-KqbW1N"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(chars_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "# Definiendo el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgz7VKwTUbj6"
      },
      "source": [
        "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas `CategoryEncoding` que transforma a índices a vectores OHE y `TimeDistributed` que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Zd2OkfQYs2Q7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed (TimeDist  (None, None, 120)         0         \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, None, 200)         64200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 120)         24120     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 88320 (345.00 KB)\n",
            "Trainable params: 88320 (345.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "\n",
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK3z85sQfUe"
      },
      "source": [
        "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
        "\n",
        "**Nota**: un Callback es una rutina gatillada por algún evento, son muy útiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cálculo cada vez que termina una epoch de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "zUHX3r5JD-MG"
      },
      "outputs": [],
      "source": [
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data, history_ppl,patience=5):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.val_data = val_data\n",
        "\n",
        "      self.target = []\n",
        "      self.padded = []\n",
        "\n",
        "      count = 0\n",
        "      self.info = []\n",
        "      self.min_score = np.inf\n",
        "      self.patience_counter = 0\n",
        "      self.patience = patience\n",
        "\n",
        "      # nos movemos en todas las secuencias de los datos de validación\n",
        "      for seq in self.val_data:\n",
        "\n",
        "        len_seq = len(seq)\n",
        "        # armamos todas las subsecuencias\n",
        "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
        "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
        "\n",
        "        if len(subseq)!=0:\n",
        "\n",
        "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
        "\n",
        "          self.info.append((count,count+len_seq))\n",
        "          count += len_seq\n",
        "\n",
        "      self.padded = np.vstack(self.padded)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        predictions = self.model.predict(self.padded,verbose=0)\n",
        "\n",
        "        # para cada secuencia de validación\n",
        "        for start,end in self.info:\n",
        "\n",
        "          # en `probs` iremos guardando las probabilidades de los términos target\n",
        "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        current_score = np.mean(scores)\n",
        "        history_ppl.append(current_score)\n",
        "        print(f'\\n mean perplexity: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que detener el entrenamiento\n",
        "        if current_score < self.min_score:\n",
        "          self.min_score = current_score\n",
        "          self.model.save(\"my_model.keras\")\n",
        "          print(\"Saved new model!\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == self.patience:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "oQq1PHDkxDvN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m 24/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:17\u001b[0m 748ms/step - loss: 3.6862"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[65], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m history_ppl \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mPplCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_sentences_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhistory_ppl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Nicolas\\anaconda3\\envs\\dataAnalysis\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Nicolas\\anaconda3\\envs\\dataAnalysis\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
            "File \u001b[1;32mc:\\Users\\Nicolas\\anaconda3\\envs\\dataAnalysis\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Nicolas\\anaconda3\\envs\\dataAnalysis\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\Nicolas\\anaconda3\\envs\\dataAnalysis\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Nicolas\\anaconda3\\envs\\dataAnalysis\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Nicolas\\anaconda3\\envs\\dataAnalysis\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\Nicolas\\anaconda3\\envs\\dataAnalysis\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[1;32mc:\\Users\\Nicolas\\anaconda3\\envs\\dataAnalysis\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\Nicolas\\anaconda3\\envs\\dataAnalysis\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
            "File \u001b[1;32mc:\\Users\\Nicolas\\anaconda3\\envs\\dataAnalysis\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model.fit(X, y, epochs=5, callbacks=[PplCallback(tokenized_sentences_val,history_ppl)], batch_size=4096)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "K30JHB3Dv-mx"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Rhy5hZN38qfO"
      },
      "outputs": [],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model = keras.models.load_model('my_model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "### Predicción del próximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBvKHFPmzpy2"
      },
      "outputs": [],
      "source": [
        "# Se puede usar gradio para probar el modelo\n",
        "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
        "# https://gradio.app/\n",
        "\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HNyBykvhzs7-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "JoFqRC5pxzqS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'habia una vez en la carra de la compañeros '"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text='habia una vez'\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "GeLqAoOYW1Hm"
      },
      "outputs": [],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=20,input=\"habia una vez\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "P8HQoLhw-NYg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([30, 17, 50,  3, 17, 56, 65,  9, 17, 56, 26, 22, 46, 56, 29,  3, 28,\n",
              "        5, 22, 41, 56, 38, 47, 58, 58, 56, 28, 22, 56, 30, 17, 50, 57])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "salidas[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "2S3_I3S1W1Hm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'habia una vez mister fogg se habí'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
