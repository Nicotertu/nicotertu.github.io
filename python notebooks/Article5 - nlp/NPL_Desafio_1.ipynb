{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq6j8LsYq1Dr"
      },
      "source": [
        "# Vectorización de texto y modelo de clasificación Naïve Bayes con el dataset 20 newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l7cXR6CI30ry"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-pVDWV_rQc"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ech9qJaUo9vK"
      },
      "outputs": [],
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), download_if_missing=True, data_home='data')\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), download_if_missing=True, data_home='data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxjSI7su_uWI"
      },
      "source": [
        "## Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-94VP0QYCzDn"
      },
      "outputs": [],
      "source": [
        "# instanciamos un vectorizador\n",
        "# ver diferentes parámetros de instanciación en la documentación de sklearn\n",
        "tfidfvect = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "ftPlyanuak8n",
        "outputId": "45a94d0e-49e7-4f7c-c806-7d5b66779dd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# en el atributo `data` accedemos al texto\n",
        "newsgroups_train.data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1zxcXV6aC_oL"
      },
      "outputs": [],
      "source": [
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador\n",
        "# (obtener el vocabulario y calcular el vector IDF)\n",
        "# y transformar directamente los datos\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sv7TXbda41-",
        "outputId": "dcca5de6-dac1-4d68-d284-ce7be2ed9e2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (11314, 101631)\n",
            "cantidad de documentos: 11314\n",
            "tamaño del vocabulario (dimensionalidad de los vectores): 101631\n"
          ]
        }
      ],
      "source": [
        "# recordar que las vectorizaciones por conteos son esparsas\n",
        "# por ello sklearn convenientemente devuelve los vectores de documentos\n",
        "# como matrices esparsas\n",
        "print(type(X_train))\n",
        "print(f'shape: {X_train.shape}')\n",
        "print(f'cantidad de documentos: {X_train.shape[0]}')\n",
        "print(f'tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgydNTZ2pAgR",
        "outputId": "95111464-e40c-4b57-d154-ede153739a82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25775"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# una vez fiteado el vectorizador, podemos acceder a atributos como el vocabulario\n",
        "# aprendido. Es un diccionario que va de términos a índices.\n",
        "# El índice es la posición en el vector de documento.\n",
        "tfidfvect.vocabulary_['car']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xnTSZuvyrTcP"
      },
      "outputs": [],
      "source": [
        "# es muy útil tener el diccionario opuesto que va de índices a términos\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swa-AgWrMSHM",
        "outputId": "93d09f31-4c42-4215-e750-a13c83ecf96a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# en `y_train` guardamos los targets que son enteros\n",
        "y_train = newsgroups_train.target\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je5kxvQMDLvf",
        "outputId": "59799046-9799-406f-c4be-81c5765de58d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clases [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# hay 20 clases correspondientes a los 20 grupos de noticias\n",
        "print(f'clases {np.unique(newsgroups_test.target)}')\n",
        "newsgroups_test.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXCICFSd_y90"
      },
      "source": [
        "## Similaridad de documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pki_olShnyE",
        "outputId": "b2bd8485-40c7-4923-c8a9-4ad6b735576e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "THE WHITE HOUSE\n",
            "\n",
            "                  Office of the Press Secretary\n",
            "                   (Pittsburgh, Pennslyvania)\n",
            "______________________________________________________________\n",
            "For Immediate Release                         April 17, 1993     \n",
            "\n",
            "             \n",
            "                  RADIO ADDRESS TO THE NATION \n",
            "                        BY THE PRESIDENT\n",
            "             \n",
            "                Pittsburgh International Airport\n",
            "                    Pittsburgh, Pennsylvania\n",
            "             \n",
            "             \n",
            "10:06 A.M. EDT\n",
            "             \n",
            "             \n",
            "             THE PRESIDENT:  Good morning.  My voice is coming to\n",
            "you this morning through the facilities of the oldest radio\n",
            "station in America, KDKA in Pittsburgh.  I'm visiting the city to\n",
            "meet personally with citizens here to discuss my plans for jobs,\n",
            "health care and the economy.  But I wanted first to do my weekly\n",
            "broadcast with the American people. \n",
            "             \n",
            "             I'm told this station first broadcast in 1920 when\n",
            "it reported that year's presidential elections.  Over the past\n",
            "seven decades presidents have found ways to keep in touch with\n",
            "the people, from whistle-stop tours to fire-side chats to the bus\n",
            "tour that I adopted, along with Vice President Gore, in last\n",
            "year's campaign.\n",
            "             \n",
            "             Every Saturday morning I take this time to talk with\n",
            "you, my fellow Americans, about the problems on your minds and\n",
            "what I'm doing to try and solve them.  It's my way of reporting\n",
            "to you and of giving you a way to hold me accountable.\n",
            "             \n",
            "             You sent me to Washington to get our government and\n",
            "economy moving after years of paralysis and policy and a bad\n",
            "experiment with trickle-down economics.  You know how important\n",
            "it is for us to make bold, comprehensive changes in the way we do\n",
            "business.  \n",
            "             \n",
            "             We live in a competitive global economy.  Nations\n",
            "rise and fall on the skills of their workers, the competitiveness\n",
            "of their companies, the imagination of their industries, and the\n",
            "cooperative experience and spirit that exists between business,\n",
            "labor and government.  Although many of the economies of the\n",
            "industrialized world are now suffering from slow growth, they've\n",
            "made many of the smart investments and the tough choices which\n",
            "our government has for too long ignored.  That's why many of them\n",
            "have been moving ahead and too many of our people have been\n",
            "falling behind.\n",
            "             \n",
            "             We have an economy today that even when it grows is\n",
            "not producing new jobs.  We've increased the debt of our nation\n",
            "by four times over the last 12 years, and we don't have much to\n",
            "show for it.  We know that wages of most working people have\n",
            "stopped rising, that most people are working longer work weeks\n",
            "and that too many families can no longer afford the escalating\n",
            "cost of health care.\n",
            "             \n",
            "             But we also know that, given the right tools, the\n",
            "right incentives and the right encouragement, our workers and\n",
            "businesses can make the kinds of products and profits our economy\n",
            "needs to expand opportunity and to make our communities better\n",
            "places to live.\n",
            "             \n",
            "             In many critical products today Americans are the\n",
            "low cost, high quality producers.  Our task is to make sure that\n",
            "we create more of those kinds of jobs.\n",
            "             \n",
            "             Just two months ago I gave Congress my plan for\n",
            "long-term jobs and economic growth.  It changes the old\n",
            "priorities in Washington and puts our emphasis where it needs to\n",
            "be -- on people's real needs, on increasing investments and jobs\n",
            "and education, on cutting the federal deficit, on stopping the\n",
            "waste which pays no dividends, and redirecting our precious\n",
            "resources toward investment that creates jobs now and lays the\n",
            "groundwork for robust economic growth in the future.\n",
            "             \n",
            "             These new directions passed the Congress in record\n",
            "time and created a new sense of hope and opportunity in our\n",
            "country.  Then the jobs plan I presented to Congress, which would\n",
            "create hundreds of thousands of jobs, most of them in the private\n",
            "sector in 1993 and 1994, passed the House of Representatives.  It\n",
            "now has the support of a majority of the United States Senate. \n",
            "But it's been held up by a filibuster of a minority in the\n",
            "Senate, just 43 senators.  They blocked a vote that they know\n",
            "would result in the passage of our bill and the creation of jobs.\n",
            "             \n",
            "             The issue isn't politics; the issue is people. \n",
            "Millions of Americans are waiting for this legislation and\n",
            "counting on it, counting on us in Washington.  But the jobs bill\n",
            "has been grounded by gridlock.  \n",
            "             \n",
            "             I know the American people are tired of business as\n",
            "usual and politics as usual.  I know they don't want us to spin\n",
            "or wheels.  They want the recovery to get moving.  So I have\n",
            "taken a first step to break this gridlock and gone the extra\n",
            "mile.  Yesterday I offered to cut the size of this plan by 25\n",
            "percent -- from $16 billion to $12 billion.  \n",
            "             \n",
            "             It's not what I'd hoped for.  With 16 million\n",
            "Americans looking for full-time work, I simply can't let the bill\n",
            "languish when I know that even a compromise bill will mean\n",
            "hundreds of thousands of jobs for our people.  The mandate is to\n",
            "act to achieve change and move the country forward.  By taking\n",
            "this initiative in the face of an unrelenting Senate talkathon, I\n",
            "think we can respond to your mandate and achieve a significant\n",
            "portion of our original goals.\n",
            "             \n",
            "             First, we want to keep the programs as much as\n",
            "possible that are needed to generate jobs and meet human needs,\n",
            "including highway and road construction, summer jobs for young\n",
            "people, immunization for children, construction of waste water\n",
            "sites, and aid to small businesses.  We also want to keep funding\n",
            "for extended unemployment compensation benefits, for people who\n",
            "have been unemployed for a long time because the economy isn't\n",
            "creating jobs.\n",
            "             \n",
            "             Second, I've recommended that all the other programs\n",
            "in the bill be cut across-the-board by a little more than 40\n",
            "percent.\n",
            "             \n",
            "             And third, I've recommended a new element in this\n",
            "program to help us immediately start our attempt to fight against\n",
            "crime by providing $200 million for cities and towns to rehire\n",
            "police officers who lost their jobs during the recession and put\n",
            "them back to work protecting our people.  I'm also going to fight\n",
            "for a tough crime bill because the people of this country need it\n",
            "and deserve it.\n",
            "             \n",
            "             Now, the people who are filibustering this bill --\n",
            "the Republican senators -- say they won't vote for it because it\n",
            "increases deficit spending, because there's extra spending this\n",
            "year that hasn't already been approved.  That sounds reasonable,\n",
            "doesn't it?  Here's what they don't say.  This program is more\n",
            "than paid for by budget cuts over my five-year budget, and this\n",
            "budget is well within the spending limits already approved by the\n",
            "Congress this year.\n",
            "             \n",
            "             It's amazing to me that many of these same senators\n",
            "who are filibustering the bill voted during the previous\n",
            "administration for billions of dollars of the same kind of\n",
            "emergency spending, and much of it was not designed to put the\n",
            "American people to work.  \n",
            "             \n",
            "             This is not about deficit spending.  We have offered\n",
            "a plan to cut the deficit.  This is about where your priorities\n",
            "are -- on people or on politics.  \n",
            "             \n",
            "             Keep in mind that our jobs bill is paid for dollar\n",
            "for dollar.  It is paid for by budget cuts.  And it's the\n",
            "soundest investment we can now make for ourselves and our\n",
            "children.  I urge all Americans to take another look at this jobs\n",
            "and investment program; to consider again the benefits for all of\n",
            "us when we've helped make more American partners working to\n",
            "ensure the future of our nation and the strength of our economy.\n",
            "             \n",
            "             You know, if every American who wanted a job had\n",
            "one, we wouldn't have a lot of the other problems we have in this\n",
            "country today.  This bill is not a miracle, it's a modest first\n",
            "step to try to set off a job creation explosion in this country\n",
            "again.  But it's a step we ought to take.  And it is fully paid\n",
            "for over the life of our budget.\n",
            "             \n",
            "             Tell your lawmakers what you think.  Tell them how\n",
            "important the bill is.  If it passes, we'll all be winners.\n",
            "             \n",
            "             Good morning, and thank you for listening.\n"
          ]
        }
      ],
      "source": [
        "# Veamos similaridad de documentos. Tomemos algún documento\n",
        "idx = 4811\n",
        "print(newsgroups_train.data[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ssa9bqJ-hA_v"
      },
      "outputs": [],
      "source": [
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_mDA7p3AzcQ",
        "outputId": "747a3923-4b1c-4e2b-921d-4ebf2b271b00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.        , 0.70930477, 0.67474953, ..., 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "np.sort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OIhDA1jAryX",
        "outputId": "04ddf3ca-0741-42d7-8bbb-00bb395f7834"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 4811,  6635,  4253, ...,  1534, 10055,  4750], dtype=int64)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# y a qué documentos corresponden\n",
        "np.argsort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hP7qLS4ZBLps"
      },
      "outputs": [],
      "source": [
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QdJLHPJACvaj",
        "outputId": "926186cf-7d4c-4bd3-927b-ad00bf7f24f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'talk.politics.misc'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# el documento original pertenece a la clase:\n",
        "newsgroups_train.target_names[y_train[idx]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWy_73epCbFG",
        "outputId": "daf534e5-b2a8-43d4-d05a-9c52b816cf69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n"
          ]
        }
      ],
      "source": [
        "# y los 5 más similares son de las clases:\n",
        "for i in mostsim:\n",
        "  print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRoNnKwhBqzq"
      },
      "source": [
        "## Modelo de clasificación Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "TPM0thDaLk0R",
        "outputId": "bc7fdc3e-d912-4e0c-9d9e-33efc97b46fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# es muy fácil instanciar un modelo de clasificación Naïve Bayes y entrenarlo con sklearn\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NrQjzM48Mu4T"
      },
      "outputs": [],
      "source": [
        "# con nuestro vectorizador ya fiteado en train, vectorizamos los textos\n",
        "# del conjunto de test\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "y_pred =  clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkGJhetEPdA4",
        "outputId": "232ee2ce-e904-466e-be57-babc1f319029"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5854345727938506"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# el F1-score es una metrica adecuada para reportar desempeño de modelos de claificación\n",
        "# es robusta al desbalance de clases. El promediado 'macro' es el promedio de los\n",
        "# F1-score de cada clase. El promedio 'micro' es equivalente a la accuracy que no\n",
        "# es una buena métrica cuando los datasets son desbalanceados\n",
        "f1_score(y_test, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McArD4rSDR2K"
      },
      "source": [
        "# Consigna del desafío 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJgf6GQIIEH1"
      },
      "source": [
        "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
        "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
        "la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
        "\n",
        "**2**. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
        "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
        "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
        "y ComplementNB.\n",
        "\n",
        "**3**. Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
        "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), download_if_missing=True, data_home='data')\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), download_if_missing=True, data_home='data')\n",
        "\n",
        "tfidfvect = TfidfVectorizer()\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}\n",
        "\n",
        "y_train = newsgroups_train.target\n",
        "\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 1\n",
        "Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
        "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
        "la similaridad según el contenido del texto y la etiqueta de clasificación.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se crea una clase que guarda los valores \n",
        "    # ID de un documento\n",
        "    # su vector de similitud de coseno\n",
        "    # dos vectores ordenados de la similitud con un documento y su respectivo ID.\n",
        "# La clase tambien tiene una funcion para encontrar la N cantidad de documentos similares (y guardar sus respectivos datos)\n",
        "class Document():\n",
        "    def __init__(self, idx):\n",
        "        self.idx = idx\n",
        "        self.cossim = cosine_similarity(X_train[self.idx], X_train)\n",
        "        self.sim = np.sort(self.cossim)[::-1]\n",
        "        self.docsim = np.argsort(self.cossim)[::-1]\n",
        "        self.class_type = newsgroups_train.target_names[y_train[self.idx]]\n",
        "        \n",
        "    def similar_documents(self, amount):\n",
        "        print(f\"Analizando documento {self.idx}, de categorias [{self.class_type}]\")\n",
        "        print(\"Los documentos mas similares son: \")\n",
        "        \n",
        "        similar_docs = []\n",
        "                    \n",
        "        for i in range(1, amount + 1):\n",
        "            idx = self.docsim[:][0][-1-i]\n",
        "            sim = self.sim[:][0][-1-i]\n",
        "            class_type = newsgroups_train.target_names[y_train[idx]]\n",
        "            print (f\"{100 * sim:.2f}% similaridad con el documento {idx} de clases [{class_type}]\")\n",
        "            \n",
        "            similar_docs.append({\n",
        "                'idx': idx,\n",
        "                'sim': sim,\n",
        "                'class_type': class_type\n",
        "            })\n",
        "            \n",
        "        return similar_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analizando documento 7338, de categorias [rec.sport.baseball]\n",
            "Los documentos mas similares son: \n",
            "37.65% similaridad con el documento 1486 de clases [rec.sport.baseball]\n",
            "28.03% similaridad con el documento 913 de clases [alt.atheism]\n",
            "27.04% similaridad con el documento 5826 de clases [soc.religion.christian]\n",
            "26.51% similaridad con el documento 10331 de clases [rec.sport.baseball]\n",
            "26.11% similaridad con el documento 4988 de clases [sci.med]\n",
            "\n",
            "Analizando documento 6473, de categorias [sci.space]\n",
            "Los documentos mas similares son: \n",
            "28.24% similaridad con el documento 6704 de clases [sci.space]\n",
            "26.56% similaridad con el documento 10344 de clases [sci.space]\n",
            "25.93% similaridad con el documento 913 de clases [alt.atheism]\n",
            "25.83% similaridad con el documento 5826 de clases [soc.religion.christian]\n",
            "25.75% similaridad con el documento 10836 de clases [alt.atheism]\n",
            "\n",
            "Analizando documento 6759, de categorias [misc.forsale]\n",
            "Los documentos mas similares son: \n",
            "98.95% similaridad con el documento 1584 de clases [misc.forsale]\n",
            "63.06% similaridad con el documento 4352 de clases [rec.sport.baseball]\n",
            "58.74% similaridad con el documento 769 de clases [misc.forsale]\n",
            "55.79% similaridad con el documento 372 de clases [misc.forsale]\n",
            "46.72% similaridad con el documento 7432 de clases [misc.forsale]\n",
            "\n",
            "Analizando documento 1370, de categorias [comp.sys.mac.hardware]\n",
            "Los documentos mas similares son: \n",
            "34.47% similaridad con el documento 5595 de clases [comp.sys.mac.hardware]\n",
            "25.20% similaridad con el documento 8589 de clases [comp.sys.mac.hardware]\n",
            "24.67% similaridad con el documento 8688 de clases [comp.sys.mac.hardware]\n",
            "22.85% similaridad con el documento 6898 de clases [comp.sys.mac.hardware]\n",
            "22.28% similaridad con el documento 4359 de clases [comp.sys.mac.hardware]\n",
            "\n",
            "Analizando documento 2124, de categorias [sci.med]\n",
            "Los documentos mas similares son: \n",
            "85.00% similaridad con el documento 4915 de clases [sci.med]\n",
            "42.03% similaridad con el documento 7130 de clases [sci.med]\n",
            "17.73% similaridad con el documento 10595 de clases [sci.med]\n",
            "15.15% similaridad con el documento 5720 de clases [sci.med]\n",
            "13.25% similaridad con el documento 7441 de clases [talk.politics.guns]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Creamos una lista para guardar 5 documentos aleatorios\n",
        "documents = []\n",
        "    \n",
        "# Creamos una de las clases anteriores para cada uno de esos 5 documentos aleatorios\n",
        "for i in range(5):\n",
        "    documents.append(\n",
        "        Document(random.randint(0, len(newsgroups_train.data) - 1))\n",
        "    )\n",
        "    \n",
        "# Guardamos las similitudes en otra lista\n",
        "similarities = []\n",
        "    \n",
        "for i in range(len(documents)):\n",
        "    similarities.append(documents[i].similar_documents(5))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Basandonos unicamente en las clases de los documentos, se puede ver con claridad que todos los articulos comparten clases en comun, y algunos difieren a lo mucho en 1 o 2 clases.\n",
        "\n",
        "Para poder verificar el contenido de los mismos, tendriamos que leer los 5 documentos originales y los 5 documentos mas similares a cada uno (es decir, 30 documentos), y alguno de ellos son muy extensos. Vamos a emplear ChatGPT para hacer esta tarea mas sencilla.\n",
        "\n",
        "Nuestro primer prompt es el siguiente:\n",
        "\n",
        "> En el siguiente mensaje que te voy a escribir, podras leer un texto. Ese es el texto original. Como respuesta al texto original, solo responde \"Entendido\". En siguientes mensajes, te voy a mandar otros textos. Como respuesta a cada texto adicional, quiero que me digas qué tanto en común tiene el documento enviado y el documento original (una breve descripción de no más de 1 párrafo), y adicionalmente des un porcentaje de similitud aproximado (sin necesidad de explicar nada)\n",
        "\n",
        "Y los posteriores prompts son los respectivos textos de los documentos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2124\n",
            "274\n",
            "585\n",
            "464\n",
            "231\n",
            "532\n",
            "5922\n"
          ]
        }
      ],
      "source": [
        "doc = 4\n",
        "# Guardar el documento original en un archivo .txt\n",
        "with open(f\"original.txt\", \"w\") as text:\n",
        "    print(documents[doc].idx)\n",
        "    print(len(newsgroups_train.data[documents[doc].idx]))\n",
        "    text.write(newsgroups_train.data[documents[doc].idx])\n",
        "        \n",
        "# Guardar los documentos similares en un archivo .txt\n",
        "for i in range(len(documents)):\n",
        "    with open(f\"document{i}.txt\", \"w\") as text:\n",
        "        print(len(newsgroups_train.data[similarities[doc][i]['idx']]))\n",
        "        text.write(newsgroups_train.data[similarities[doc][i]['idx']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Documento 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Respuesta al documento 1:\n",
        "\n",
        "> El documento similar discute la valoración de la libertad, sugiriendo que aunque muchas personas consideran que la libertad es valiosa, no es universalmente aceptada como un valor objetivo. Ambos textos tratan sobre la libertad y su valor percibido, pero difieren en sus conclusiones sobre su objetividad.\n",
        "\n",
        "> Porcentaje de similitud: 70%\n",
        "\n",
        "Respuesta al documento 2:\n",
        "\n",
        "> El documento similar aborda la relación entre la ciencia, los valores y la moralidad objetiva, sugiriendo que la ciencia, aunque basada en hechos observables, está influenciada por los valores de los observadores. Además, discute la idea de una moralidad objetiva en el contexto de la existencia de un Dios omnipotente. Ambos textos tratan sobre la objetividad en diferentes contextos (valores y moralidad), pero con enfoques distintos.\n",
        "\n",
        "> Porcentaje de similitud: 60%\n",
        "\n",
        "Respuesta al documento 3:\n",
        "\n",
        "> El documento similar expresa una opinión subjetiva sobre la libertad y discute la falta de consenso sobre su significado, cuestionando cómo un valor puede ser objetivo si su definición no lo es. Ambos textos tratan sobre la libertad y su valoración, pero el documento similar enfatiza más la subjetividad y la variabilidad en la interpretación del término.\n",
        "\n",
        "> Porcentaje de similitud: 75%\n",
        "\n",
        "Respuesta al documento 4:\n",
        "\n",
        "> El documento similar critica el uso de la palabra \"objetivo\" en relación con \"valores\" y señala la subjetividad inherente a conceptos como el valor y la moralidad. Sugiere que términos como \"objetivo\" y \"subjetivo\" deben ser claramente definidos para evitar malentendidos, concluyendo que no existe una moralidad objetiva. Ambos textos tratan sobre la objetividad en valores y moralidad, pero el documento similar se centra en la precisión terminológica y la subjetividad de estos conceptos.\n",
        "\n",
        "> Porcentaje de similitud: 65%\n",
        "\n",
        "Respuesta al documento 5:\n",
        "\n",
        "> El documento similar analiza la definición de \"valores\" en diferentes contextos, concluyendo que en el contexto científico, los valores se basan en hechos observables, mientras que en un sistema moral, los valores son principios considerados deseables. Argumenta que la ciencia no se basa en valores morales objetivos y cuestiona la posibilidad de una moralidad objetiva. Ambos textos abordan la relación entre valores, objetividad y moralidad, pero desde ángulos distintos, enfocándose en la precisión terminológica y la naturaleza subjetiva de la moralidad.\n",
        "\n",
        "> Porcentaje de similitud: 70%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Documento 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Respuesta al documento 1:\n",
        "\n",
        "> El documento similar tiene en común con el documento original el uso de frases en inglés, la estructura de mensaje en un formato informal y la referencia a \"DoD #8177 = Technician(Dr. Speed) .NOT. Student\". Ambos textos mantienen un tono conversacional e informal, y ambos mencionan un identificador de DoD junto con una posición.\n",
        "\n",
        "> Porcentaje de similitud: 70%\n",
        "\n",
        "Respuesta al documento 2:\n",
        "\n",
        "> El documento similar comparte con el documento original el uso de frases en inglés, la estructura informal del mensaje y la referencia a \"DoD #8177 = Technician(Dr. Speed) .NOT. Student\". Ambos textos también utilizan un identificador de DoD junto con una posición, manteniendo un tono conversacional e informal.\n",
        "\n",
        "> Porcentaje de similitud: 60%\n",
        "\n",
        "Respuesta al documento 3:\n",
        "\n",
        "> El documento similar comparte con el documento original el uso de frases en inglés y la estructura informal del mensaje. Ambos textos mencionan \"DoD #8177 = Technician(Dr. Speed) .NOT. Student\" como una firma distintiva. Sin embargo, el contenido específico del mensaje es diferente, enfocándose en un tema técnico relacionado con Plexi-Fairings en lugar de referencias a situaciones o preguntas.\n",
        "\n",
        "> Porcentaje de similitud: 50%\n",
        "\n",
        "Respuesta al documento 4:\n",
        "\n",
        "> El documento similar comparte con el documento original el uso de frases en inglés, la estructura informal del mensaje y la firma distintiva \"DoD #8177 = Technician(Dr. Speed) .NOT. Student\". Sin embargo, el contenido se centra en películas y sus temas, lo que es diferente del contenido del documento original.\n",
        "\n",
        "> Porcentaje de similitud: 55%\n",
        "\n",
        "Respuesta al documento 5:\n",
        "\n",
        "> El documento similar comparte con el documento original el uso de frases en inglés, la estructura informal del mensaje y la firma distintiva \"DoD #8177 = Technician(Dr. Speed) .NOT. Student\". Ambos textos mantienen un tono conversacional y mencionan temas relacionados con motocicletas. Sin embargo, el contenido específico es diferente, centrándose en una anécdota sobre motocicletas adaptadas para personas en silla de ruedas.\n",
        "\n",
        "> Porcentaje de similitud: 65%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Documento 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Respuesta al documento 1:\n",
        "\n",
        "> El documento similar comparte el tema de los problemas de calidad con los productos Emerson, específicamente en equipos electrónicos. Ambos textos mencionan fallas y experiencias negativas con productos de la misma marca. Sin embargo, el documento similar es más detallado y anecdótico, mientras que el original es más conciso y directo.\n",
        "\n",
        "> Porcentaje de similitud: 60%\n",
        "\n",
        "Respuesta al documento 2:\n",
        "\n",
        "> El documento similar sugiere un problema específico con el flyback en un Magnavox, similar al comentario sobre el flyback en el documento original. Ambos textos están centrados en diagnosticar problemas técnicos en televisores de diferentes marcas.\n",
        "\n",
        "> Porcentaje de similitud: 70%\n",
        "\n",
        "Respuesta al documento 3:\n",
        "\n",
        "> El documento similar proporciona una explicación técnica sobre la posible causa del problema en un televisor, específicamente relacionado con la pérdida de vacío del tubo de imagen y los posibles efectos secundarios, como una explosión. Esto complementa la discusión técnica sobre problemas de televisores en el documento original.\n",
        "\n",
        "> Porcentaje de similitud: 75%\n",
        "\n",
        "Respuesta al documento 4:\n",
        "\n",
        "> El documento similar parece tomar un tono humorístico o sarcástico en respuesta a la discusión técnica sobre problemas de televisores. Este contraste con el tono técnico del documento original proporciona una perspectiva diferente sobre el tema discutido.\n",
        "\n",
        "> Porcentaje de similitud: 50%\n",
        "\n",
        "Respuesta al documento 5:\n",
        "\n",
        "> El documento similar comparte una experiencia personal con un televisor de marca Goldstar, que es similar en diseño y componentes electrónicos al modelo mencionado en el documento original. Ambos textos discuten problemas técnicos específicos relacionados con el circuito del televisor y la reparación utilizando esquemas y componentes de repuesto.\n",
        "\n",
        "> Porcentaje de similitud: 80%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Documento 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este documento tuve que cambiar de ChatGPT a Gemini, ya que ChatGPT se enfrascó en un loop de solo responder \"Entendido.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Respuesta al documento 1:\n",
        "\n",
        "> Both documents discuss a serious topic (movies in the original document, hell and salvation in this document).\n",
        "\n",
        "> Similarity: 10%\n",
        "\n",
        "Respuesta al documento 2:\n",
        "\n",
        "> The document is similar to the original document in that they both discuss cars, but the focus here is on renting a car and the insurance involved, whereas the original document was unspecified.\n",
        "\n",
        "> Similarity: 50%\n",
        "\n",
        "Respuesta al documento 3:\n",
        "\n",
        "> Both documents discuss entertainment (watching movies in the original document, watching a documentary in this document).\n",
        "\n",
        "> Similarity: 10%\n",
        "\n",
        "Respuesta al documento 4:\n",
        "\n",
        "> Both documents discuss using technology for entertainment purposes (watching movies in the original document, capturing monitor output for potentially entertainment purposes in this document).\n",
        "\n",
        "> Similarity: 20%\n",
        "\n",
        "Respuesta al documento 5:\n",
        "\n",
        "> This document is similar to the original document in that they both discuss mechanical issues with playback devices. However, the original document focused on movies, while this one focuses on cassette tapes.\n",
        "\n",
        "> Similarity: 30%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Documento 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este documento (idx 9054) y sus documentos similares hablan de muertes, asesinatos y suicidios en Israel, motivo por el cual Gemini no quiso responder.\n",
        "\n",
        "> While I aim to be helpful, Google Search may provide a more detailed and accurate response on this topic.\n",
        "\n",
        "El documento original habla de un carro con pasajero suicida lleno de gas butano que explotó en el medio de dos buses. El documento mas similar 1 y 2 son dos perspectivas distintas del mismo suceso, mientras que el documento 3 y 5 habla acerca de la diferencia entre matar y asesinar en tiempos de guerra. Por otro lado, el documento 4 habla de varios incidentes ocurridos en el mismo lugar de la explosion del carro con pasajero suicida del documento original."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 2\n",
        "\n",
        "Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
        "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
        "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
        "y ComplementNB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.44      0.50       319\n",
            "           1       0.65      0.71      0.68       389\n",
            "           2       0.72      0.52      0.60       394\n",
            "           3       0.59      0.71      0.65       392\n",
            "           4       0.72      0.70      0.71       385\n",
            "           5       0.81      0.74      0.78       395\n",
            "           6       0.83      0.72      0.77       390\n",
            "           7       0.75      0.73      0.74       396\n",
            "           8       0.76      0.73      0.75       398\n",
            "           9       0.93      0.81      0.87       397\n",
            "          10       0.60      0.93      0.73       399\n",
            "          11       0.72      0.75      0.74       396\n",
            "          12       0.72      0.58      0.64       393\n",
            "          13       0.82      0.78      0.80       396\n",
            "          14       0.76      0.79      0.77       394\n",
            "          15       0.56      0.89      0.68       398\n",
            "          16       0.58      0.73      0.65       364\n",
            "          17       0.82      0.81      0.81       376\n",
            "          18       0.62      0.45      0.52       310\n",
            "          19       0.51      0.19      0.27       251\n",
            "\n",
            "    accuracy                           0.70      7532\n",
            "   macro avg       0.70      0.69      0.68      7532\n",
            "weighted avg       0.71      0.70      0.69      7532\n",
            "\n",
            "El mejor parametro fue [{'alpha': 0.01}]\n"
          ]
        }
      ],
      "source": [
        "clf_mnb = MultinomialNB()\n",
        "\n",
        "# Parámetros a probar en el grid search\n",
        "parameters = {\n",
        "    'alpha': (1, 0.5, 0.1, 1e-2, 1e-3)\n",
        "}\n",
        "\n",
        "# Configuración de GridSearchCV\n",
        "kf_mnb = KFold(n_splits=5, shuffle=True)\n",
        "grid_search_mnb = GridSearchCV(clf_mnb, parameters, cv=kf_mnb, n_jobs=-1, verbose=1, scoring='f1_macro')\n",
        "\n",
        "# Entrenamiento y ajuste del modelo\n",
        "grid_search_mnb.fit(X_train, y_train)\n",
        "\n",
        "# Predicción y evaluación en conjunto de prueba\n",
        "y_pred = grid_search_mnb.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"El mejor parametro fue [{grid_search_mnb.best_params_}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.46      0.38       319\n",
            "           1       0.71      0.72      0.72       389\n",
            "           2       0.77      0.53      0.63       394\n",
            "           3       0.62      0.70      0.66       392\n",
            "           4       0.75      0.72      0.74       385\n",
            "           5       0.81      0.78      0.80       395\n",
            "           6       0.76      0.71      0.73       390\n",
            "           7       0.78      0.74      0.76       396\n",
            "           8       0.80      0.77      0.78       398\n",
            "           9       0.91      0.85      0.88       397\n",
            "          10       0.87      0.94      0.91       399\n",
            "          11       0.73      0.80      0.76       396\n",
            "          12       0.72      0.57      0.64       393\n",
            "          13       0.79      0.78      0.78       396\n",
            "          14       0.78      0.79      0.79       394\n",
            "          15       0.54      0.88      0.67       398\n",
            "          16       0.60      0.72      0.65       364\n",
            "          17       0.80      0.83      0.81       376\n",
            "          18       0.65      0.42      0.51       310\n",
            "          19       0.56      0.18      0.27       251\n",
            "\n",
            "    accuracy                           0.71      7532\n",
            "   macro avg       0.71      0.70      0.69      7532\n",
            "weighted avg       0.72      0.71      0.71      7532\n",
            "\n",
            "El mejor parametro fue [{'alpha': 0.1, 'norm': True}]\n"
          ]
        }
      ],
      "source": [
        "clf_cnb = ComplementNB()\n",
        "\n",
        "# Parámetros a probar en el grid search\n",
        "parameters_cnb = {\n",
        "    'alpha': (1, 0.5, 0.1, 1e-2, 1e-3),\n",
        "    'norm': (True, False)\n",
        "}\n",
        "\n",
        "# Configuración de GridSearchCV\n",
        "kf_cnb = KFold(n_splits=5, shuffle=True) \n",
        "grid_search_cnb = GridSearchCV(clf_cnb, parameters_cnb, cv=kf_cnb, n_jobs=-1, verbose=1, scoring='f1_macro')\n",
        "\n",
        "# Entrenamiento y ajuste del modelo\n",
        "grid_search_cnb.fit(X_train, y_train)\n",
        "\n",
        "# Predicción y evaluación en conjunto de prueba\n",
        "y_pred2 = grid_search_cnb.predict(X_test)\n",
        "print(classification_report(y_test, y_pred2))\n",
        "print(f\"El mejor parametro fue [{grid_search_cnb.best_params_}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 3\n",
        "\n",
        "Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
        "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_T = X_train.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word: was       \t| idx: 95844\n",
            "Similar word: the \t| idx: 88532 \t| Similitud: 48.33%\n",
            "Similar word: that \t| idx: 88519 \t| Similitud: 42.20%\n",
            "Similar word: of \t| idx: 67670 \t| Similitud: 41.10%\n",
            "Similar word: in \t| idx: 49447 \t| Similitud: 40.80%\n",
            "Similar word: and \t| idx: 18521 \t| Similitud: 40.23%\n",
            "\n",
            "Word: text       \t| idx: 88422\n",
            "Similar word: scrollbar \t| idx: 81125 \t| Similitud: 27.56%\n",
            "Similar word: millennia \t| idx: 61780 \t| Similitud: 25.36%\n",
            "Similar word: suprising \t| idx: 86568 \t| Similitud: 22.65%\n",
            "Similar word: insertion \t| idx: 50243 \t| Similitud: 19.96%\n",
            "Similar word: tove \t| idx: 89694 \t| Similitud: 19.42%\n",
            "\n",
            "Word: mom       \t| idx: 62907\n",
            "Similar word: tatoos \t| idx: 87820 \t| Similitud: 68.64%\n",
            "Similar word: virile \t| idx: 94452 \t| Similitud: 68.64%\n",
            "Similar word: snm6394 \t| idx: 83622 \t| Similitud: 60.65%\n",
            "Similar word: ultb \t| idx: 91540 \t| Similitud: 58.43%\n",
            "Similar word: rit \t| idx: 78514 \t| Similitud: 58.39%\n",
            "\n",
            "Word: human       \t| idx: 47765\n",
            "Similar word: beings \t| idx: 22220 \t| Similitud: 24.81%\n",
            "Similar word: nestorianism \t| idx: 65492 \t| Similitud: 21.29%\n",
            "Similar word: rights \t| idx: 78415 \t| Similitud: 19.70%\n",
            "Similar word: of \t| idx: 67670 \t| Similitud: 19.23%\n",
            "Similar word: adressed \t| idx: 16971 \t| Similitud: 18.90%\n",
            "\n",
            "Word: building       \t| idx: 24562\n",
            "Similar word: injecting \t| idx: 50096 \t| Similitud: 21.36%\n",
            "Similar word: parroted \t| idx: 69978 \t| Similitud: 20.88%\n",
            "Similar word: belch \t| idx: 22242 \t| Similitud: 20.88%\n",
            "Similar word: burning \t| idx: 24732 \t| Similitud: 20.35%\n",
            "Similar word: ramming \t| idx: 75983 \t| Similitud: 20.26%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "words_of_interest = random.choices(list(tfidfvect.vocabulary_), k=5)\n",
        "# El diccionario contiene algunas palabras extrañas por corrupcion de palabras o documentos no filtrados. Preseleccioné algunas palabras para un mejor analisis.\n",
        "words_of_interest = ['was', 'text', 'mom', 'human', 'building']\n",
        "\n",
        "for word in words_of_interest:\n",
        "    word_idx = tfidfvect.vocabulary_.get(word)\n",
        "    print(f\"Word: {word}       \\t| idx: {word_idx}\")\n",
        "\n",
        "    cossim = cosine_similarity(X_train_T[word_idx], X_train_T)[0]\n",
        "    sorted_cossim = np.sort(cossim)[::-1][1:6]\n",
        "    mostsim = np.argsort(cossim)[::-1][1:6]\n",
        "    \n",
        "    a=0\n",
        "    for idx in mostsim:\n",
        "        print(f\"Similar word: {idx2word[idx]} \\t| idx: {idx} \\t| Similitud: {100 * sorted_cossim[a]:.2f}%\")\n",
        "        a+=1\n",
        "    \n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para palabras de usos comunes, las palabras mas similares resultan coherentes:\n",
        "\n",
        " - Para _was_, las palabras mas similares son pronombres, articulos, preposiciones, etc. lo cual tiene sentido, ya que _was_ viene acompañado de ellas.\n",
        " - Para _text_, hay palabras similares como _scrollbar_, _surprising_ e _insertion_ que tienen sentido juntas, y otras que tienen algunos usos mas inusuales pero dependen de los documentos como _millenia_ y _tove_\n",
        " - Para _mom_, vemos una palabra interesante: _tatoos_. Los tatuajes pueden estar relacionado que es usual tatuarse el nombre de la madre de uno. _Virile_ deberia verse en el contexto en que es utilizada en estos documentos para entender la similitud. En este caso, aparecen tres palabras bastante inusuales: _snm6394_, _ultb_ y _rit_ que pueden estar relacionadas a documentos no filtrados.\n",
        " - Para _human_ si vemos 5 palabras similares que van de la mano.\n",
        " - Para _building_ vemos cinco palabras que estan relacionadas con accidentes, lo cual nos podria llevar a creer que los documentos tienen noticias de distintos sucesos que ocurrieron en edificios."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
