{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenización por caracteres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, GRU\n",
        "from keras.layers import TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.special import softmax\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "\n",
        "El dataset seleccionado es un libro en ingles llamado \"Odyssey of the Dragonlords\". Este libro es una aventura prediseñada para Dungeons Masters y la version 5.0 de Dungeons & Dragons. El documento original está en formato .pdf y se utilizaron herramientas online para transformarlo a .txt.\n",
        "\n",
        "A grandes rasgos, este libro desarrolla el camino que emprende un grupo de aventureros en un entorno similar a la mitologia griega (con dioses e historia específicos del setting del libro) para salvar a su mundo de la perdición, y cómo ellos logran ascender a la divinidad en el proceso.\n",
        "\n",
        "Por cuestiones de tiempos de entrenamiento y para facilitar probar distintos tipos de modelo, se redujo a la introduccion (20 paginas) de este libro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"Odyssey of the Dragonlords - char.txt\", \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "    article_text = \"\".join(line.strip() for line in lines)\n",
        "\n",
        "# en article text se encuentra el texto de todo el libro\n",
        "article_text = article_text.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
        "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulario: 36 letras\n"
          ]
        }
      ],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100\n",
        "\n",
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(article_text)\n",
        "vocab_size = len(chars_vocab)\n",
        "\n",
        "# la longitud de vocabulario de caracteres es:\n",
        "print(f\"Vocabulario: {vocab_size} letras\")\n",
        "\n",
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29315"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]\n",
        "len(tokenized_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WSSmg9jtKP0T"
      },
      "outputs": [],
      "source": [
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]\n",
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vken7O4ETsAJ"
      },
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
        "\n",
        "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
        "\n",
        "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(26215, 100)\n",
            "[ 5 12 14 28  6 13 12 34 19  6]\n",
            "[12 14 28  6 13 12 34 19  6 34]\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)\n",
        "print(X[0,:10])\n",
        "print(y[0,:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "## Definiendo los modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "### Definir el modelo con RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Nicolas\\anaconda3\\envs\\dataAnalysis\\Lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">47,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">80,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │        \u001b[38;5;34m47,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │        \u001b[38;5;34m80,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)       │         \u001b[38;5;34m7,236\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,836</span> (526.70 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,836\u001b[0m (526.70 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,836</span> (526.70 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,836\u001b[0m (526.70 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_RNN = Sequential()\n",
        "model_RNN.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model_RNN.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model_RNN.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model_RNN.add(Dense(vocab_size, activation='softmax'))\n",
        "model_RNN.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "model_RNN.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK3z85sQfUe"
      },
      "source": [
        "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
        "\n",
        "**Nota**: un Callback es una rutina gatillada por algún evento, son muy útiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cálculo cada vez que termina una epoch de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data, history_ppl, patience=5, nn_type='RNN'):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.val_data = val_data\n",
        "      self.target = []\n",
        "      self.padded = []\n",
        "      self.nn_type = nn_type\n",
        "\n",
        "      count = 0\n",
        "      self.info = []\n",
        "      self.min_score = np.inf\n",
        "      self.patience_counter = 0\n",
        "      self.patience = patience\n",
        "\n",
        "      # nos movemos en todas las secuencias de los datos de validación\n",
        "      for seq in self.val_data:\n",
        "\n",
        "        len_seq = len(seq)\n",
        "        # armamos todas las subsecuencias\n",
        "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
        "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
        "\n",
        "        if len(subseq)!=0:\n",
        "\n",
        "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
        "\n",
        "          self.info.append((count,count+len_seq))\n",
        "          count += len_seq\n",
        "\n",
        "      self.padded = np.vstack(self.padded)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        predictions = self.model.predict(self.padded,verbose=0)\n",
        "\n",
        "        # para cada secuencia de validación\n",
        "        for start,end in self.info:\n",
        "\n",
        "          # en `probs` iremos guardando las probabilidades de los términos target\n",
        "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        current_score = np.mean(scores)\n",
        "        history_ppl[self.nn_type].append(current_score)\n",
        "        print(f'\\n mean perplexity: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que detener el entrenamiento\n",
        "        if current_score < self.min_score:\n",
        "          self.min_score = current_score\n",
        "          self.model.save(f\"my_model{self.nn_type}.keras\")\n",
        "          print(\"Saved new model!\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == self.patience:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definir el modelo con GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos el modelo con neuronas tipo GRU (Gated recurrent units). Este tipo de unidad ayuda a solucionar el problema de vanishing gradient (cuando los gradientes de los pesos de la red se vuelven muy pequeños, lo que dificulta el aprendizaje).\n",
        "\n",
        "Las unidades GRU son una simplificacion de las LSTM, ya que utilizan una sola compuerta para controlar el flujo de informacion hacia la celda de memoria. Este tipo de unidad es mas efectiva cuando se requiere que la red aprenda rapido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">142,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">241,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │       \u001b[38;5;34m142,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │       \u001b[38;5;34m241,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)       │         \u001b[38;5;34m7,236\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">391,236</span> (1.49 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m391,236\u001b[0m (1.49 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">391,236</span> (1.49 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m391,236\u001b[0m (1.49 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_GRU = Sequential()\n",
        "model_GRU.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model_GRU.add(GRU(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model_GRU.add(GRU(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model_GRU.add(Dense(vocab_size, activation='softmax'))\n",
        "model_GRU.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "model_GRU.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definir el modelo con LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos el modelo con neuronas tipo LSTM (long short term memory). Al igual que las GRU, este tipo de unidad ayuda con el problema de vanishing gradient. Pero lo hace por medio de tres compuertas en vez de una: input, output y forget.\n",
        "\n",
        "Este tipo de unidad es efectiva para tareas mas complejas y que requieran memoria a largo plazo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">189,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">320,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │       \u001b[38;5;34m189,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │       \u001b[38;5;34m320,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)       │         \u001b[38;5;34m7,236\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">517,636</span> (1.97 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m517,636\u001b[0m (1.97 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">517,636</span> (1.97 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m517,636\u001b[0m (1.97 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_LSTM = Sequential()\n",
        "model_LSTM.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model_LSTM.add(LSTM(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "model_LSTM.add(LSTM(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "model_LSTM.add(Dense(vocab_size, activation='softmax'))\n",
        "model_LSTM.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "model_LSTM.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 2.8714\n",
            " mean perplexity: 9.533387161312813 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 2.8686\n",
            "Epoch 2/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 2.1990\n",
            " mean perplexity: 8.802680182175846 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 149ms/step - loss: 2.1986\n",
            "Epoch 3/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 2.0510\n",
            " mean perplexity: 8.29821406215687 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 146ms/step - loss: 2.0507\n",
            "Epoch 4/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.9266\n",
            " mean perplexity: 8.549950778232688 \n",
            "\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 141ms/step - loss: 1.9263\n",
            "Epoch 5/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 1.8243\n",
            " mean perplexity: 7.822582473687018 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 141ms/step - loss: 1.8240\n",
            "Epoch 6/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.7360\n",
            " mean perplexity: 8.065926839405465 \n",
            "\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 142ms/step - loss: 1.7358\n",
            "Epoch 7/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.6694\n",
            " mean perplexity: 7.932273956526637 \n",
            "\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 143ms/step - loss: 1.6692\n",
            "Epoch 8/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.6096\n",
            " mean perplexity: 8.04436101120893 \n",
            "\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 143ms/step - loss: 1.6095\n",
            "Epoch 9/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.5652\n",
            " mean perplexity: 8.030688827772964 \n",
            "\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 144ms/step - loss: 1.5651\n",
            "Epoch 10/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.5242\n",
            " mean perplexity: 8.093611686379761 \n",
            "\n",
            "Stopping training...\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 142ms/step - loss: 1.5241\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = {\n",
        "    \"RNN\": [],\n",
        "    \"GRU\": [],\n",
        "    \"LSTM\": []\n",
        "}\n",
        "hist = model_RNN.fit(X, y, epochs=10, callbacks=[PplCallback(tokenized_sentences_val,history_ppl[\"RNN\"], nn_type='RNN')], batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - loss: 2.9951\n",
            " mean perplexity: 11.201584645138908 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 428ms/step - loss: 2.9933\n",
            "Epoch 2/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - loss: 2.4283\n",
            " mean perplexity: 9.736111554759828 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 403ms/step - loss: 2.4278\n",
            "Epoch 3/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - loss: 2.2937\n",
            " mean perplexity: 9.248917425699773 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 403ms/step - loss: 2.2935\n",
            "Epoch 4/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - loss: 2.2061\n",
            " mean perplexity: 8.775617562594212 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 404ms/step - loss: 2.2059\n",
            "Epoch 5/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - loss: 2.1123\n",
            " mean perplexity: 8.421453913399104 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 404ms/step - loss: 2.1121\n",
            "Epoch 6/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: 2.0103\n",
            " mean perplexity: 8.457454632077223 \n",
            "\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 405ms/step - loss: 2.0101\n",
            "Epoch 7/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: 1.9177\n",
            " mean perplexity: 8.097109369048148 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 405ms/step - loss: 1.9174\n",
            "Epoch 8/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: 1.8244\n",
            " mean perplexity: 7.925785895844917 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 408ms/step - loss: 1.8242\n",
            "Epoch 9/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - loss: 1.7397\n",
            " mean perplexity: 7.662183676730201 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 408ms/step - loss: 1.7395\n",
            "Epoch 10/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - loss: 1.6588\n",
            " mean perplexity: 7.667442879645702 \n",
            "\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 421ms/step - loss: 1.6587\n"
          ]
        }
      ],
      "source": [
        "hist = model_GRU.fit(X, y, epochs=10, callbacks=[PplCallback(tokenized_sentences_val,history_ppl[\"GRU\"], nn_type='GRU')], batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - loss: 3.0491\n",
            " mean perplexity: 17.21611817692677 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 505ms/step - loss: 3.0482\n",
            "Epoch 2/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - loss: 2.9072\n",
            " mean perplexity: 16.281178545962025 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 477ms/step - loss: 2.9071\n",
            "Epoch 3/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - loss: 2.7999\n",
            " mean perplexity: 12.372885865198068 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 478ms/step - loss: 2.7992\n",
            "Epoch 4/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - loss: 2.5304\n",
            " mean perplexity: 10.588292766966564 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 475ms/step - loss: 2.5301\n",
            "Epoch 5/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - loss: 2.4099\n",
            " mean perplexity: 10.173585654686983 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 476ms/step - loss: 2.4097\n",
            "Epoch 6/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - loss: 2.3329\n",
            " mean perplexity: 9.932213303805955 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 464ms/step - loss: 2.3327\n",
            "Epoch 7/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - loss: 2.2684\n",
            " mean perplexity: 9.350407523058276 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 464ms/step - loss: 2.2683\n",
            "Epoch 8/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - loss: 2.2113\n",
            " mean perplexity: 9.639501488694766 \n",
            "\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 466ms/step - loss: 2.2112\n",
            "Epoch 9/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - loss: 2.1581\n",
            " mean perplexity: 8.983240349897125 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 463ms/step - loss: 2.1580\n",
            "Epoch 10/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - loss: 2.1033\n",
            " mean perplexity: 9.204890070956873 \n",
            "\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 463ms/step - loss: 2.1032\n"
          ]
        }
      ],
      "source": [
        "hist = model_LSTM.fit(X, y, epochs=10, callbacks=[PplCallback(tokenized_sentences_val,history_ppl[\"LSTM\"], nn_type='LSTM')], batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Entrenamiento\n",
        "sns.lineplot(x=range(1, len(history_ppl['RNN']) + 1), y=history_ppl['RNN'], label='RNN')\n",
        "sns.lineplot(x=range(1, len(history_ppl['GRU']) + 1), y=history_ppl['GRU'], label='GRU')\n",
        "sns.lineplot(x=range(1, len(history_ppl['LSTM']) + 1), y=history_ppl['LSTM'], label='LSTM')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model_RNN = keras.models.load_model('my_modelRNN.keras')\n",
        "model_GRU = keras.models.load_model('my_modelGRU.keras')\n",
        "model_LSTM = keras.models.load_model('my_modelLSTM.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "### Predicción del próximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model_RNN.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Probamos generando una secuencia que empiece con \"the smartest \" (el mas inteligente)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the first war and the dragonlords and the dr\n",
            "the first war of the five gods. the city of \n",
            "the first war the cites of the fire the fith\n"
          ]
        }
      ],
      "source": [
        "input_text='the first war '\n",
        "\n",
        "print(generate_seq(model_RNN, input_text, max_length=max_context_size, n_words=30))\n",
        "print(generate_seq(model_GRU, input_text, max_length=max_context_size, n_words=30))\n",
        "print(generate_seq(model_LSTM, input_text, max_length=max_context_size, n_words=30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para redes relativamente sencillas como las que se implementaron, y para tiempos de entrenamiento relativamente cortos (10 epocas), podemos ver que la red mas elocuente es la RNN.\n",
        "\n",
        "La simpleza de esta red permite obtener una respuesta aceptable con poco entrenamiento. Por otro lado, la red GRU muestra resultados un poco mejores que la LSTM, lo cual concuerda con la perplejidad medida durante el entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Probamos obtener secuencias por medio de beam search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the dragonlords were the lord of sydon and lutheria\n",
            "the dragonlords were the dragonlords of the dragonl\n",
            "the dragonlords were the great of thylea. the great\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search\n",
        "salidasRNN = beam_search(model_RNN,num_beams=10,num_words=30,input=\"the dragonlords were \")\n",
        "print(decode(salidasRNN[0]))\n",
        "\n",
        "#salidasGRU = beam_search(model_GRU,num_beams=10,num_words=30,input=\"with the help of the \")\n",
        "salidasGRU = beam_search(model_GRU,num_beams=10,num_words=30,input=\"the dragonlords were \")\n",
        "print(decode(salidasGRU[0]))\n",
        "\n",
        "#salidasLSTM = beam_search(model_LSTM,num_beams=10,num_words=30,input=\"sadly it was the defeat \")\n",
        "salidasLSTM = beam_search(model_LSTM,num_beams=10,num_words=30,input=\"the dragonlords were \")\n",
        "print(decode(salidasLSTM[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este caso, sale a relucir mas la red LSTM. La red RNN da informacion erronea (los dragonlords son los enemigos de sydon y lutheria), lo que evidencia la falta de memoria que las otras redes tienen.\n",
        "\n",
        "La red GRU rapidamente se estanca en un loop de \"the dragonlords of\" mientras que la LSTM consigue arrojar una oracion coherente y alusiva al texto original."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
